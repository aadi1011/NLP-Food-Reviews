{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd8ddec6",
   "metadata": {},
   "source": [
    "# Natural Language Processing on Amazon Fine Food Reviews\n",
    "## Assignment 2\n",
    "\n",
    "**Aadith Sukumar**<br>\n",
    "**AIML A1**<br>\n",
    "**21070126003**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e051a7",
   "metadata": {},
   "source": [
    "Data Source: [Kaggle](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews?resource=download)\n",
    "\n",
    "Questions:\n",
    "1. Use the same dataset from Assignment 1.\n",
    "\n",
    "2. DO FOLLOWING Preprocessing STEPS using NLTK or SpaCy:\n",
    "    1. Remove empty rows. Remove duplicates.\n",
    "    2. Tokenization, Lemmatization\n",
    "    3. Data Cleansing: Remove stopwords, remove symbols,remove emojis,     remove URLS, remove http tags, remove excess whitespaces.\n",
    "    4. Lower the strings, replace abbreviations, fix contractions.\n",
    "\n",
    "3. Use following as range of values for input variables:\n",
    "    1. For 1st set of results use:\n",
    "      1. batch_size = 4\n",
    "      2. max_sequence_length = 50\n",
    "      2. embedding_dim = 50\n",
    "      2. max_words = 10000\n",
    "      2. lstm_units = 32\n",
    "     \n",
    "    2. For 2st set of results use:\n",
    "      1. batch_size = 8\n",
    "      1. max_sequence_length = 30\n",
    "      1. embedding_dim = 30\n",
    "      1. max_words = 25000\n",
    "      1. lstm_units = 32\n",
    "\n",
    "4. Use following LSTM:\n",
    "    1. Single Layer of LSTM for 1st set of results\n",
    "    2. Two Layers of LSTM for 2nd set of results\n",
    "\n",
    "5. Compare the results using Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ece46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep  2 11:04:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 527.41       Driver Version: 527.41       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000   WDDM  | 00000000:2D:00.0  On |                  Off |\n",
      "| 41%   38C    P8    10W / 140W |    296MiB / 16376MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3920    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A      6452    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      7336    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7360    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8888    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11400    C+G   ...938.62\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     12492    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     13156    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0be3ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sit\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20763313",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295b6c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download(\"all\")\n",
    "import spacy\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from gensim.models import Word2Vec\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21850d",
   "metadata": {},
   "source": [
    "## 1. Loading The Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8ddda7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Reviews.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4423985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:  (568454, 10)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data: \",data.shape)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c6080",
   "metadata": {},
   "source": [
    "## Sampling Data for Faster Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc66b592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381574</th>\n",
       "      <td>381575</td>\n",
       "      <td>B0035R36QU</td>\n",
       "      <td>A187VKK7VWKQ99</td>\n",
       "      <td>Food Snob</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1317945600</td>\n",
       "      <td>Smells and Taste like Fish</td>\n",
       "      <td>The picture is NOT the color of the salt. It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60005</th>\n",
       "      <td>60006</td>\n",
       "      <td>B000E48IPG</td>\n",
       "      <td>A15V9LJDW699AQ</td>\n",
       "      <td>Justanotherguy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1283817600</td>\n",
       "      <td>Part of a Healthy Breakfast</td>\n",
       "      <td>Some students of nutrition believe that it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365964</th>\n",
       "      <td>365965</td>\n",
       "      <td>B008IY5EGU</td>\n",
       "      <td>AMLU3405N8CUI</td>\n",
       "      <td>Gretchen F.</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1344902400</td>\n",
       "      <td>Sticking with original Pop Chips</td>\n",
       "      <td>I am a HUGE fan of Pop Chips and buy them regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456899</th>\n",
       "      <td>456900</td>\n",
       "      <td>B001EO5S2Q</td>\n",
       "      <td>A2E3WMF9RWW2X2</td>\n",
       "      <td>K. Duvall</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1203638400</td>\n",
       "      <td>Great crunch and tasty.</td>\n",
       "      <td>These were very good.  Good crunch and low sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412626</th>\n",
       "      <td>412627</td>\n",
       "      <td>B004725ZX4</td>\n",
       "      <td>A3EA67H2C3R6VF</td>\n",
       "      <td>Java \"Mom of one\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1298937600</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Everyone who comes to my house LOVES these cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277462</th>\n",
       "      <td>277463</td>\n",
       "      <td>B000VK8AVK</td>\n",
       "      <td>A2UEO5XR3598GI</td>\n",
       "      <td>Rich K</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1296691200</td>\n",
       "      <td>YUMMY, YUMMY a little bit of love for your Tummy</td>\n",
       "      <td>Hey!!  these things taste good. At first I tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391411</th>\n",
       "      <td>391412</td>\n",
       "      <td>B000F9XB7K</td>\n",
       "      <td>AD6XWLNH2X8S7</td>\n",
       "      <td>WILLOBIE</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1283990400</td>\n",
       "      <td>Still better than the imitators.</td>\n",
       "      <td>My local stores have not been stocking Red Ova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341933</th>\n",
       "      <td>341934</td>\n",
       "      <td>B000ESJR20</td>\n",
       "      <td>A316RLHHO9Y24T</td>\n",
       "      <td>myoho guy</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>1219363200</td>\n",
       "      <td>Mount Hagen vs Taster's Choice</td>\n",
       "      <td>I like freshly-ground, brewed coffee, but some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319899</th>\n",
       "      <td>319900</td>\n",
       "      <td>B0018QIPS4</td>\n",
       "      <td>A234HXDATOAYEY</td>\n",
       "      <td>Karen Baker \"city mama\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1280793600</td>\n",
       "      <td>Addictive!</td>\n",
       "      <td>I started buying these as a non-messy way for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364465</th>\n",
       "      <td>364466</td>\n",
       "      <td>B000PDY3HI</td>\n",
       "      <td>A1VYU7DCJ3GA9E</td>\n",
       "      <td>Katy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338249600</td>\n",
       "      <td>LOVE this popcorn!!!</td>\n",
       "      <td>This is a GREAT item -- very easy to use and y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId              ProfileName  \\\n",
       "381574  381575  B0035R36QU  A187VKK7VWKQ99                Food Snob   \n",
       "60005    60006  B000E48IPG  A15V9LJDW699AQ           Justanotherguy   \n",
       "365964  365965  B008IY5EGU   AMLU3405N8CUI              Gretchen F.   \n",
       "456899  456900  B001EO5S2Q  A2E3WMF9RWW2X2                K. Duvall   \n",
       "412626  412627  B004725ZX4  A3EA67H2C3R6VF        Java \"Mom of one\"   \n",
       "277462  277463  B000VK8AVK  A2UEO5XR3598GI                   Rich K   \n",
       "391411  391412  B000F9XB7K   AD6XWLNH2X8S7                 WILLOBIE   \n",
       "341933  341934  B000ESJR20  A316RLHHO9Y24T                myoho guy   \n",
       "319899  319900  B0018QIPS4  A234HXDATOAYEY  Karen Baker \"city mama\"   \n",
       "364465  364466  B000PDY3HI  A1VYU7DCJ3GA9E                     Katy   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "381574                     2                       9      1  1317945600   \n",
       "60005                      0                       0      5  1283817600   \n",
       "365964                    14                      16      1  1344902400   \n",
       "456899                     0                       0      5  1203638400   \n",
       "412626                     0                       0      5  1298937600   \n",
       "277462                     2                       2      5  1296691200   \n",
       "391411                     6                       6      5  1283990400   \n",
       "341933                    52                      53      5  1219363200   \n",
       "319899                     0                       0      5  1280793600   \n",
       "364465                     0                       0      5  1338249600   \n",
       "\n",
       "                                                 Summary  \\\n",
       "381574                        Smells and Taste like Fish   \n",
       "60005                        Part of a Healthy Breakfast   \n",
       "365964                  Sticking with original Pop Chips   \n",
       "456899                           Great crunch and tasty.   \n",
       "412626                                           Awesome   \n",
       "277462  YUMMY, YUMMY a little bit of love for your Tummy   \n",
       "391411                  Still better than the imitators.   \n",
       "341933                    Mount Hagen vs Taster's Choice   \n",
       "319899                                        Addictive!   \n",
       "364465                              LOVE this popcorn!!!   \n",
       "\n",
       "                                                     Text  \n",
       "381574  The picture is NOT the color of the salt. It s...  \n",
       "60005   Some students of nutrition believe that it is ...  \n",
       "365964  I am a HUGE fan of Pop Chips and buy them regu...  \n",
       "456899  These were very good.  Good crunch and low sug...  \n",
       "412626  Everyone who comes to my house LOVES these cra...  \n",
       "277462  Hey!!  these things taste good. At first I tho...  \n",
       "391411  My local stores have not been stocking Red Ova...  \n",
       "341933  I like freshly-ground, brewed coffee, but some...  \n",
       "319899  I started buying these as a non-messy way for ...  \n",
       "364465  This is a GREAT item -- very easy to use and y...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampling data to get 10000 rows\n",
    "data = data.sample(n=10000)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b447133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data:  (10000, 10)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 381574 to 32509\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Id                      10000 non-null  int64 \n",
      " 1   ProductId               10000 non-null  object\n",
      " 2   UserId                  10000 non-null  object\n",
      " 3   ProfileName             10000 non-null  object\n",
      " 4   HelpfulnessNumerator    10000 non-null  int64 \n",
      " 5   HelpfulnessDenominator  10000 non-null  int64 \n",
      " 6   Score                   10000 non-null  int64 \n",
      " 7   Time                    10000 non-null  int64 \n",
      " 8   Summary                 9999 non-null   object\n",
      " 9   Text                    10000 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 859.4+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data: \",data.shape)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12231cb2",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e056bda",
   "metadata": {},
   "source": [
    "### a. Lemmatization with Spacy & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bedc8c54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1042, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\", line 419, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ssl.py\", line 501, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ssl.py\", line 1041, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ssl.py\", line 1310, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "TimeoutError: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 489, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\", line 550, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\", line 769, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 703, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 386, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1042, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\", line 419, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 449, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ssl.py\", line 501, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ssl.py\", line 1041, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ssl.py\", line 1310, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "urllib3.exceptions.ProtocolError: ('Connection aborted.', TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\Scripts\\spacy-script.py\", line 10, in <module>\n",
      "    sys.exit(setup_cli())\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\cli\\_util.py\", line 71, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 1659, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\typer\\main.py\", line 532, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\cli\\download.py\", line 35, in download_cli\n",
      "    download(model, direct, sdist, *ctx.args)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\cli\\download.py\", line 67, in download\n",
      "    compatibility = get_compatibility()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\cli\\download.py\", line 78, in get_compatibility\n",
      "    r = requests.get(about.__compatibility__)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 587, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 701, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 547, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))\n"
     ]
    }
   ],
   "source": [
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1456714",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "data['Text'] = data['Text'].apply(lambda x: nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "560e1f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406847</th>\n",
       "      <td>406848</td>\n",
       "      <td>B004H4QZDQ</td>\n",
       "      <td>A2M5VD2YDK2LQL</td>\n",
       "      <td>Robert L. Spencer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1319155200</td>\n",
       "      <td>Great soup but nothing like the picture</td>\n",
       "      <td>[I, really, likd, the, soup, ,, but, it, was, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166456</th>\n",
       "      <td>166457</td>\n",
       "      <td>B000FA39GW</td>\n",
       "      <td>A13NIU1KP9TI5P</td>\n",
       "      <td>Ali \"MI Matriarch\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1269388800</td>\n",
       "      <td>Childhood Favorite</td>\n",
       "      <td>[These, cookies, are, one, of, those, childhoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId         ProfileName  \\\n",
       "406847  406848  B004H4QZDQ  A2M5VD2YDK2LQL   Robert L. Spencer   \n",
       "166456  166457  B000FA39GW  A13NIU1KP9TI5P  Ali \"MI Matriarch\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "406847                     0                       0      4  1319155200   \n",
       "166456                     0                       0      5  1269388800   \n",
       "\n",
       "                                        Summary  \\\n",
       "406847  Great soup but nothing like the picture   \n",
       "166456                       Childhood Favorite   \n",
       "\n",
       "                                                     Text  \n",
       "406847  [I, really, likd, the, soup, ,, but, it, was, ...  \n",
       "166456  [These, cookies, are, one, of, those, childhoo...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "data['Text'] = data['Text'].apply(lambda x: [item.text for item in x])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a139856",
   "metadata": {},
   "source": [
    "### b. Stop Words, Symbols, URLs and Special Characters Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7ea333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406847</th>\n",
       "      <td>406848</td>\n",
       "      <td>B004H4QZDQ</td>\n",
       "      <td>A2M5VD2YDK2LQL</td>\n",
       "      <td>Robert L. Spencer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1319155200</td>\n",
       "      <td>Great soup but nothing like the picture</td>\n",
       "      <td>[I, likd, soup, ,, liquid, vegetables, ,, They...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166456</th>\n",
       "      <td>166457</td>\n",
       "      <td>B000FA39GW</td>\n",
       "      <td>A13NIU1KP9TI5P</td>\n",
       "      <td>Ali \"MI Matriarch\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1269388800</td>\n",
       "      <td>Childhood Favorite</td>\n",
       "      <td>[These, cookies, childhood, favorites, help, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId         ProfileName  \\\n",
       "406847  406848  B004H4QZDQ  A2M5VD2YDK2LQL   Robert L. Spencer   \n",
       "166456  166457  B000FA39GW  A13NIU1KP9TI5P  Ali \"MI Matriarch\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "406847                     0                       0      4  1319155200   \n",
       "166456                     0                       0      5  1269388800   \n",
       "\n",
       "                                        Summary  \\\n",
       "406847  Great soup but nothing like the picture   \n",
       "166456                       Childhood Favorite   \n",
       "\n",
       "                                                     Text  \n",
       "406847  [I, likd, soup, ,, liquid, vegetables, ,, They...  \n",
       "166456  [These, cookies, childhood, favorites, help, p...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stop words\n",
    "data['Text'] = data['Text'].apply(lambda x: [item for item in x if item not in STOP_WORDS])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe3a2be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406847</th>\n",
       "      <td>406848</td>\n",
       "      <td>B004H4QZDQ</td>\n",
       "      <td>A2M5VD2YDK2LQL</td>\n",
       "      <td>Robert L. Spencer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1319155200</td>\n",
       "      <td>Great soup but nothing like the picture</td>\n",
       "      <td>[I, likd, soup, liquid, vegetables, They, look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166456</th>\n",
       "      <td>166457</td>\n",
       "      <td>B000FA39GW</td>\n",
       "      <td>A13NIU1KP9TI5P</td>\n",
       "      <td>Ali \"MI Matriarch\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1269388800</td>\n",
       "      <td>Childhood Favorite</td>\n",
       "      <td>[These, cookies, childhood, favorites, help, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId         ProfileName  \\\n",
       "406847  406848  B004H4QZDQ  A2M5VD2YDK2LQL   Robert L. Spencer   \n",
       "166456  166457  B000FA39GW  A13NIU1KP9TI5P  Ali \"MI Matriarch\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "406847                     0                       0      4  1319155200   \n",
       "166456                     0                       0      5  1269388800   \n",
       "\n",
       "                                        Summary  \\\n",
       "406847  Great soup but nothing like the picture   \n",
       "166456                       Childhood Favorite   \n",
       "\n",
       "                                                     Text  \n",
       "406847  [I, likd, soup, liquid, vegetables, They, look...  \n",
       "166456  [These, cookies, childhood, favorites, help, a...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove symbols and special characters\n",
    "data['Text'] = data['Text'].apply(lambda x: [item for item in x if item.isalpha()])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4e5fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406847</th>\n",
       "      <td>406848</td>\n",
       "      <td>B004H4QZDQ</td>\n",
       "      <td>A2M5VD2YDK2LQL</td>\n",
       "      <td>Robert L. Spencer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1319155200</td>\n",
       "      <td>Great soup but nothing like the picture</td>\n",
       "      <td>[I, likd, soup, liquid, vegetables, They, look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166456</th>\n",
       "      <td>166457</td>\n",
       "      <td>B000FA39GW</td>\n",
       "      <td>A13NIU1KP9TI5P</td>\n",
       "      <td>Ali \"MI Matriarch\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1269388800</td>\n",
       "      <td>Childhood Favorite</td>\n",
       "      <td>[These, cookies, childhood, favorites, help, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId         ProfileName  \\\n",
       "406847  406848  B004H4QZDQ  A2M5VD2YDK2LQL   Robert L. Spencer   \n",
       "166456  166457  B000FA39GW  A13NIU1KP9TI5P  Ali \"MI Matriarch\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "406847                     0                       0      4  1319155200   \n",
       "166456                     0                       0      5  1269388800   \n",
       "\n",
       "                                        Summary  \\\n",
       "406847  Great soup but nothing like the picture   \n",
       "166456                       Childhood Favorite   \n",
       "\n",
       "                                                     Text  \n",
       "406847  [I, likd, soup, liquid, vegetables, They, look...  \n",
       "166456  [These, cookies, childhood, favorites, help, a...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# urls\n",
    "data['Text'] = data['Text'].apply(lambda x: [item for item in x if \"http\" not in item])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ff94f",
   "metadata": {},
   "source": [
    "### Lowering the string, fix contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df6db06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406847</th>\n",
       "      <td>406848</td>\n",
       "      <td>B004H4QZDQ</td>\n",
       "      <td>A2M5VD2YDK2LQL</td>\n",
       "      <td>Robert L. Spencer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1319155200</td>\n",
       "      <td>Great soup but nothing like the picture</td>\n",
       "      <td>[i, likd, soup, liquid, vegetables, they, look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166456</th>\n",
       "      <td>166457</td>\n",
       "      <td>B000FA39GW</td>\n",
       "      <td>A13NIU1KP9TI5P</td>\n",
       "      <td>Ali \"MI Matriarch\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1269388800</td>\n",
       "      <td>Childhood Favorite</td>\n",
       "      <td>[these, cookies, childhood, favorites, help, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId         ProfileName  \\\n",
       "406847  406848  B004H4QZDQ  A2M5VD2YDK2LQL   Robert L. Spencer   \n",
       "166456  166457  B000FA39GW  A13NIU1KP9TI5P  Ali \"MI Matriarch\"   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "406847                     0                       0      4  1319155200   \n",
       "166456                     0                       0      5  1269388800   \n",
       "\n",
       "                                        Summary  \\\n",
       "406847  Great soup but nothing like the picture   \n",
       "166456                       Childhood Favorite   \n",
       "\n",
       "                                                     Text  \n",
       "406847  [i, likd, soup, liquid, vegetables, they, look...  \n",
       "166456  [these, cookies, childhood, favorites, help, a...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contraction_mapping = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'd\": \"who would\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who're\": \"who are\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"'s\": \" is\",\n",
    "    \"'ll\": \" will\",\n",
    "    \"'d\": \" would\",\n",
    "    \"'ve\": \" have\",\n",
    "    \"'re\": \" are\",\n",
    "    \"n't\": \" not\",\n",
    "}\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: [contraction_mapping.get(item, item) for item in x])\n",
    "data['Text'] = data['Text'].apply(lambda x: [item.lower() for item in x])\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5eebf1",
   "metadata": {},
   "source": [
    "## 3. Preparing LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463462f",
   "metadata": {},
   "source": [
    "### For 1st set of results use:\n",
    "    1. batch_size = 4\n",
    "    2. max_sequence_length = 50\n",
    "    3. embedding_dim = 50\n",
    "    4. max_words = 10000\n",
    "    5. lstm_units = 32\n",
    "    6. Single Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78fef323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras.preprocessing\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras.preprocessing) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from keras.preprocessing) (1.23.5)\n",
      "Installing collected packages: keras.preprocessing\n",
      "Successfully installed keras.preprocessing-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a401914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model with batch size 4, max sequence length 50, embedding dim 50, max words 10000, lstm units 32\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "add30d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 10000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['Text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['Text'].values)\n",
    "X = pad_sequences(X)\n",
    "y = pd.get_dummies(data['Score']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c4c8ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6700, 1234) (3300, 1234)\n",
      "(6700, 5) (3300, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8164d7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1234, 50)          500000    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 1234, 50)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                10624     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 510,789\n",
      "Trainable params: 510,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_one = Sequential()\n",
    "model_one.add(Embedding(max_fatures, 50, input_length=X.shape[1]))\n",
    "model_one.add(SpatialDropout1D(0.4))\n",
    "model_one.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_one.add(Dense(5, activation='softmax'))\n",
    "model_one.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_one.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4065a3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.9347 - accuracy: 0.6697WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 460s 275ms/step - loss: 0.9347 - accuracy: 0.6697\n",
      "Epoch 2/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.7574 - accuracy: 0.7184WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 463s 276ms/step - loss: 0.7574 - accuracy: 0.7184\n",
      "Epoch 3/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.7685WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 464s 277ms/step - loss: 0.6211 - accuracy: 0.7685\n",
      "Epoch 4/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.5104 - accuracy: 0.8082WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 462s 276ms/step - loss: 0.5104 - accuracy: 0.8082\n",
      "Epoch 5/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.8446WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 464s 277ms/step - loss: 0.4309 - accuracy: 0.8446\n",
      "Epoch 6/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8687WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 465s 278ms/step - loss: 0.3586 - accuracy: 0.8687\n",
      "Epoch 7/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.3084 - accuracy: 0.8890WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 474s 283ms/step - loss: 0.3084 - accuracy: 0.8890\n",
      "Epoch 8/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.2521 - accuracy: 0.9112WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 469s 280ms/step - loss: 0.2521 - accuracy: 0.9112\n",
      "Epoch 9/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.2090 - accuracy: 0.9304WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 470s 281ms/step - loss: 0.2090 - accuracy: 0.9304\n",
      "Epoch 10/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9333WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 471s 281ms/step - loss: 0.1904 - accuracy: 0.9333\n",
      "Epoch 11/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.9478WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 473s 282ms/step - loss: 0.1576 - accuracy: 0.9478\n",
      "Epoch 12/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9578WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 472s 282ms/step - loss: 0.1265 - accuracy: 0.9578\n",
      "Epoch 13/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9564WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 468s 279ms/step - loss: 0.1277 - accuracy: 0.9564\n",
      "Epoch 14/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.9667WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 468s 280ms/step - loss: 0.0974 - accuracy: 0.9667\n",
      "Epoch 15/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9707WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 470s 280ms/step - loss: 0.0890 - accuracy: 0.9707\n",
      "Epoch 16/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9731WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 467s 279ms/step - loss: 0.0793 - accuracy: 0.9731\n",
      "Epoch 17/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.9733WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 469s 280ms/step - loss: 0.0785 - accuracy: 0.9733\n",
      "Epoch 18/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.9804WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 469s 280ms/step - loss: 0.0586 - accuracy: 0.9804\n",
      "Epoch 19/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.9821WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 469s 280ms/step - loss: 0.0591 - accuracy: 0.9821\n",
      "Epoch 20/20\n",
      "1675/1675 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9816WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1675/1675 [==============================] - 467s 279ms/step - loss: 0.0566 - accuracy: 0.9816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17e84259ca0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_one.fit(X_train, y_train, epochs=20, batch_size=4, callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.01, patience=7, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3027552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_one.save('model_one.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f6968",
   "metadata": {},
   "source": [
    "### For 2nd set of results use:\n",
    "    1. batch_size = 8\n",
    "    2. max_sequence_length = 30\n",
    "    3. embedding_dim = 30\n",
    "    4. max_words = 25000\n",
    "    5. lstm_units = 32\n",
    "    6. Two Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1fc7d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model with batch size 8, max sequence length 30, embedding dim 30, max words 25000, lstm units 32\n",
    "\n",
    "max_features = 25000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['Text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['Text'].values)\n",
    "X = pad_sequences(X)\n",
    "y = pd.get_dummies(data['Score']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b8876df-08f9-45aa-a916-49886ada6007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a21beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6700, 1279) (3300, 1279)\n",
      "(6700, 5) (3300, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cd24b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1279, 30)          750000    \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 1279, 30)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1279, 32)          8064      \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 766,549\n",
      "Trainable params: 766,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_two = Sequential()\n",
    "model_two.add(Embedding(max_features, 30, input_length=X.shape[1]))\n",
    "model_two.add(SpatialDropout1D(0.4))\n",
    "model_two.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model_two.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_two.add(Dense(5, activation='softmax'))\n",
    "model_two.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_two.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a726e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "838/838 [==============================] - 614s 729ms/step - loss: 0.3323 - accuracy: 0.8721\n",
      "Epoch 2/20\n",
      "838/838 [==============================] - 608s 726ms/step - loss: 0.2732 - accuracy: 0.8996\n",
      "Epoch 3/20\n",
      "407/838 [=============>................] - ETA: 5:10 - loss: 0.2557 - accuracy: 0.9057"
     ]
    }
   ],
   "source": [
    "model_two.fit(X_train, y_train, epochs=20, batch_size=8, callbacks=[EarlyStopping(monitor='loss', min_delta=0.01, patience=7, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e64f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two.save('model_two.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81010782-4b62-4325-a28a-025b6cad095b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c122e3d-dd2f-450e-af38-28efe592d070",
   "metadata": {},
   "source": [
    "## Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c634da66-9b2a-43be-af8e-ca0f1e65a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fa9ba690-3233-47f8-935a-339557f854c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Reviews.csv\")\n",
    "data = data.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cafaa1be-e9c4-4824-8c03-59ba6ae8c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 10000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['Text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['Text'].values)\n",
    "X = pad_sequences(X, maxlen=433)\n",
    "y = pd.get_dummies(data['Score']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8595f116-f635-40d6-9dbc-59e604c4174f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6700, 433) (3300, 433)\n",
      "(6700, 5) (3300, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7df38edf-b3b7-48e4-af81-482e071a4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one = load_model('model_one.h5', compile=False)\n",
    "model_one.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "62784a52-86ff-4bd3-81b8-8631dfb75b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 4s 29ms/step - loss: 3.6179 - accuracy: 0.5642\n",
      "loss of model 1:  3.6178691387176514 accuracy of model 1:  0.564242422580719\n"
     ]
    }
   ],
   "source": [
    "loss_m1, accuracy_m1 = model_one.evaluate(X_test, y_test)\n",
    "print(\"loss of model 1: \", loss_m1, \"accuracy of model 1: \", accuracy_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5ba4873b-a2ed-45bf-b588-cdc059da4ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 3s 28ms/step\n",
      "[[1.0638024e-06 3.2071828e-08 8.2952107e-07 7.3840516e-07 9.9999738e-01]\n",
      " [2.0340972e-06 4.9299075e-08 6.3931896e-07 2.2569320e-06 9.9999499e-01]\n",
      " [1.6369984e-02 4.5352869e-02 6.3043994e-01 1.7141470e-01 1.3642256e-01]\n",
      " ...\n",
      " [4.4416352e-05 1.3472097e-06 1.5721776e-05 1.7671134e-04 9.9976176e-01]\n",
      " [1.3842887e-06 2.5430678e-08 1.1531790e-06 2.3747602e-06 9.9999511e-01]\n",
      " [8.9920559e-06 4.2243559e-07 2.3523769e-05 4.5122990e-05 9.9992192e-01]]\n"
     ]
    }
   ],
   "source": [
    "predictions_m1 = model_one.predict(X_test)\n",
    "print(predictions_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7d114163-bc34-4488-85eb-deed8a9ea1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 25000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['Text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['Text'].values)\n",
    "X = pad_sequences(X, maxlen=446)\n",
    "y = pd.get_dummies(data['Score']).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f84b2d90-9b40-4d02-9688-1be65913a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = load_model('model_two.h5', compile=False)\n",
    "model_two.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9ba21c11-9ddf-407d-942d-1bb2734986f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 6s 54ms/step - loss: 2.8901 - accuracy: 0.4782\n",
      "loss of model 2:  2.8901052474975586 accuracy of model 2:  0.4781818091869354\n"
     ]
    }
   ],
   "source": [
    "loss_m2, accuracy_m2 = model_two.evaluate(X_test, y_test)\n",
    "print(\"loss of model 2: \", loss_m2, \"accuracy of model 2: \", accuracy_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c0e8ecfc-6709-4f0d-90e9-70fc1a113a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 6s 54ms/step\n",
      "[[1.4336625e-05 1.4083895e-06 8.1047829e-06 7.2286732e-04 9.9925321e-01]\n",
      " [2.2305366e-04 1.2349457e-04 1.5455611e-03 7.5510740e-02 9.2259717e-01]\n",
      " [9.0441294e-03 3.8708073e-01 5.8392346e-01 1.8992374e-02 9.5926132e-04]\n",
      " ...\n",
      " [2.9513609e-05 4.5135880e-06 3.2139142e-05 2.4919466e-03 9.9744189e-01]\n",
      " [1.4858582e-05 1.9242018e-06 1.9953321e-05 1.4632988e-03 9.9849999e-01]\n",
      " [1.7404795e-05 2.1904339e-06 1.5458783e-05 1.3657188e-03 9.9859923e-01]]\n"
     ]
    }
   ],
   "source": [
    "predictions_m2 = model_two.predict(X_test)\n",
    "print(predictions_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7050de08-8b75-45d6-98cb-a1ac90d4714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare results using Classification Report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3c2ecbf5-f7d0-49fd-95c0-6ad4aeef228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.02      0.04       295\n",
      "           1       0.15      0.02      0.03       175\n",
      "           2       0.06      0.02      0.03       244\n",
      "           3       0.16      0.09      0.11       458\n",
      "           4       0.64      0.85      0.73      2128\n",
      "\n",
      "    accuracy                           0.56      3300\n",
      "   macro avg       0.22      0.20      0.19      3300\n",
      "weighted avg       0.45      0.56      0.49      3300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.01      0.01       295\n",
      "           1       0.06      0.02      0.03       175\n",
      "           2       0.02      0.01      0.02       244\n",
      "           3       0.13      0.22      0.17       458\n",
      "           4       0.64      0.69      0.66      2128\n",
      "\n",
      "    accuracy                           0.48      3300\n",
      "   macro avg       0.18      0.19      0.18      3300\n",
      "weighted avg       0.44      0.48      0.45      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), predictions_m1.argmax(axis=1)))\n",
    "print(classification_report(y_test.argmax(axis=1), predictions_m2.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194763a2-c0b2-4557-ae26-9977400b4621",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "END OF FILE\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
